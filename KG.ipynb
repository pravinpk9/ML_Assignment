{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ce5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem.wordnet import WordNetLemmatizer       #lemmatization\n",
    "from nltk.corpus.reader import NOUN, VERB, ADJ, ADV\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string #punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import os #read documents\n",
    "import re #url\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB             #Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics                            #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.ensemble import RandomForestClassifier    #RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier #GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE              #Recursive Feature Elimination\n",
    "from sklearn import metrics\n",
    "\n",
    "stop_en = stopwords.words(\"english\")\n",
    "punctuation_translator = str.maketrans(\"\",\"\",string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13eda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document_and_remove_messy_text(path, stop_words, punctuation_translator):\n",
    "    file = open(path, 'rb');\n",
    "    content = file.read()\n",
    "    words = word_tokenize(str(content))\n",
    "    \n",
    "    words_without_punctuation = []  \n",
    "    for word in words:\n",
    "        word = word.translate(punctuation_translator)\n",
    "        if len(word)>2:  #don't add empty strings or irrelevant one\n",
    "            words_without_punctuation.append(word)\n",
    "    #print(words_without_punctuation)\n",
    "    \n",
    "    words_without_stop_words_and_punctuation = [word for word in words_without_punctuation if not word in stop_en]\n",
    "    #print(words_without_stop_words_and_punctuation)\n",
    "    \n",
    "    words_without_stop_words_punctuation_and_url = []\n",
    "    for word in words_without_stop_words_and_punctuation:\n",
    "        word = re.sub(r\"http\\S+\", \"\", word)\n",
    "        words_without_stop_words_punctuation_and_url.append(word)\n",
    "    \n",
    "    #print(words_without_stop_words_punctuation_and_url)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "    tag_map['N'] = wordnet.NOUN\n",
    "    tag_map['J'] = wordnet.ADJ\n",
    "    tag_map['V'] = wordnet.VERB\n",
    "    tag_map['R'] = wordnet.ADV\n",
    "    \n",
    "    tags = nltk.pos_tag(words_without_stop_words_punctuation_and_url)\n",
    "    lemmas = [lemmatizer.lemmatize(token,tag_map[tag[0]]) for token,tag in tags]\n",
    "    \n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_documents(folder_path, stop_words, punctuation_translator):\n",
    "    file_names = os.listdir(folder_path)\n",
    "    documents = [read_document_and_remove_messy_text(folder_path+'/'+file_name, stop_words, punctuation_translator) \n",
    "                 for file_name in file_names]\n",
    "    return documents\n",
    "\n",
    "negative_docs = clean_all_documents(\"txt_sentoken/neg\",stop_en, punctuation_translator)\n",
    "positive_docs = clean_all_documents(\"txt_sentoken/pos\",stop_en, punctuation_translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4049d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents_string_array = []\n",
    "for i in range(len(negative_docs)):\n",
    "    sentence = ' '.join(negative_docs[i])\n",
    "    all_documents_string_array.append(sentence)\n",
    "for i in range(len(positive_docs)):\n",
    "    sentence = ' '.join(positive_docs[i])\n",
    "    all_documents_string_array.append(sentence)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 5000, binary=True) #play with this value\n",
    "def vectorize_occurences(corpus, vectorizer):\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    return X\n",
    "\n",
    "def calculate_frequencies(corpus):\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit(corpus)\n",
    "    X = tf_transformer.transform(corpus)\n",
    "    return X\n",
    "\n",
    "bag_of_words_occurences = vectorize_occurences(all_documents_string_array, vectorizer)\n",
    "bag_of_words_frequencies = calculate_frequencies(bag_of_words_occurences)\n",
    "#print(bag_of_words_frequencies)    #https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_documents_for_each_class = int(len(negative_docs))\n",
    "negative_labels = np.zeros((1,number_of_documents_for_each_class), dtype=int)[0]\n",
    "positive_labels = np.ones((1,number_of_documents_for_each_class), dtype=int)[0]\n",
    "#1000 0 for negatives and 1000 1 for positives\n",
    "\n",
    "negative_bow = bag_of_words_frequencies[:number_of_documents_for_each_class]\n",
    "positive_bow = bag_of_words_frequencies[number_of_documents_for_each_class:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Multinomial Naive Bayes Classifier\n",
    "gnb = MultinomialNB()           #good\n",
    "def multinomial_calssifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold):\n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(features_training_set, labels_training_set)\n",
    "    #Predict the response for test dataset\n",
    "    pred = gnb.predict(features_test_set)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Multinomial Naive Bayes Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(metrics.confusion_matrix(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold):   #best\n",
    "    clf = RandomForestClassifier(n_estimators = 1000)\n",
    "    #rfe = RFE(estimator=clf, step=0.5)\n",
    "    clf = clf.fit(features_training_set, labels_training_set)     #maybe use rfe instean of clf??\n",
    "    pred = clf.predict(features_test_set)\n",
    "    print(\"Random Forest Classifier Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold):  #asa si asa\n",
    "    clf = GradientBoostingClassifier(n_estimators=100)\n",
    "    clf = clf.fit(features_training_set, labels_training_set)\n",
    "    pred = clf.predict(features_test_set)\n",
    "    print(\"Gradient Boosting Classifier Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold):  #best\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf = clf.fit(features_training_set, labels_training_set)\n",
    "    pred = clf.predict(features_test_set)\n",
    "    print(\"SVM Classifier Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61973c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold): #good\n",
    "    clf = svm.LinearSVC()\n",
    "    clf = clf.fit(features_training_set, labels_training_set)\n",
    "    pred = clf.predict(features_test_set)\n",
    "    print(\"Linear SVM Classifier Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5442194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy, fold):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    clf = clf.fit(features_training_set, labels_training_set)\n",
    "    pred = clf.predict(features_test_set)\n",
    "    print(\"Logistic Regression Classifier Accuracy:\",metrics.accuracy_score(labels_test_set, pred))\n",
    "    average_accuracy += metrics.accuracy_score(labels_test_set, pred)\n",
    "    print(\"Average accuracy: \", average_accuracy/fold)\n",
    "    print(\"\")\n",
    "    print(metrics.classification_report(labels_test_set, pred))\n",
    "    print(\"\")\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaef7c",
   "metadata": {},
   "source": [
    "### Multinomial Calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  \n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       \n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           \n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()               \n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "    \n",
    "    average_accuracy = multinomial_calssifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold)\n",
    "\n",
    "    print('---------- Completed Multinomial Calssifier --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abf565",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  # 1800 x 5000  this 5000 depends -> 1250\n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       # 200 x 5000\n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           # 1 x 1800\n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()                # 1 x 200\n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "    \n",
    "    #average_accuracy = random_forest_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold)\n",
    "    \n",
    "    print('---------- Completed Random Forest Classifier --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3ce5a",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  # 1800 x 5000  this 5000 depends -> 1250\n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       # 200 x 5000\n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           # 1 x 1800\n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()                # 1 x 200\n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "    \n",
    "    average_accuracy = gradient_boosting_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold)\n",
    "    \n",
    "    print('---------- Completed Gradient Boosting Classifier --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb62ba0",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  # 1800 x 5000  this 5000 depends -> 1250\n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       # 200 x 5000\n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           # 1 x 1800\n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()                # 1 x 200\n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "    \n",
    "    average_accuracy = logistic_regression_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold) \n",
    "    \n",
    "    print('---------- Completed Logistic Regression Classifier --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a25f3",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c74eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  # 1800 x 5000  this 5000 depends -> 1250\n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       # 200 x 5000\n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           # 1 x 1800\n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()                # 1 x 200\n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "\n",
    "    average_accuracy = svm_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold)\n",
    "    \n",
    "    print('---------- Completed SVM Classifier --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09c013",
   "metadata": {},
   "source": [
    "### SVM Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for greater accuracy\n",
    "kfold = KFold(n_splits = 5)  \n",
    "fold = 0; average_accuracy = 0;\n",
    "\n",
    "for train, test in kfold.split(negative_bow):\n",
    "    fold = fold+1\n",
    "    features_training_set = negative_bow[train].toarray().tolist()  \n",
    "    features_training_set += positive_bow[train].toarray().tolist()\n",
    "\n",
    "    features_test_set = negative_bow[test].toarray().tolist()       \n",
    "    features_test_set += positive_bow[test].toarray().tolist()\n",
    "    \n",
    "    labels_training_set = negative_labels[train].tolist()           \n",
    "    labels_training_set += positive_labels[train].tolist()\n",
    "    \n",
    "    labels_test_set = negative_labels[test].tolist()                \n",
    "    labels_test_set += positive_labels[test].tolist()\n",
    "    \n",
    "    average_accuracy = svm_linear_classifier(features_training_set, labels_training_set, features_test_set, labels_test_set, average_accuracy ,fold)\n",
    "\n",
    "    print('---------- Completed SVM Linear Classifier --------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b669b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
